{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1366ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from mistralai import Mistral\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a02be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84be87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(api_key=OPENROUTER_API_KEY, base_url=\"https://openrouter.ai/api/v1\")\n",
    "mistral = Mistral(api_key=MISTRAL_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbec5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = \"openai/gpt-4o\"\n",
    "mistral_model = \"ministral-8b-2410\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbe119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c164a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1442c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the project had a lot of layers!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(model=gpt_model, messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1e9050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you call a data scientist who doesn't know how to code? A data scientist!\n"
     ]
    }
   ],
   "source": [
    "mistral_response = mistral.chat.complete(\n",
    "    model=mistral_model,\n",
    "    messages=prompts\n",
    ")\n",
    "print(mistral_response.choices[0].message.content)"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "markdown",
   "id": "2a5c2f5a",
   "metadata": {},
   "source": [
    "### Adversarial conversation between chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "790a29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "mistral_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "mistral_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7887a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, mistral in zip(gpt_messages, mistral_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": mistral})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c949e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, \"hi\"? Is that the best you could come up with? I expected a bit more creativity!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2398c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_mistral():\n",
    "    messages = []\n",
    "    for gpt, mistral_message in zip(gpt_messages, mistral_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": mistral_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    response = mistral.chat.complete(\n",
    "        model=mistral_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee926a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_mistral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af352ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh, so now we're starting with \"hi\"? How original. What's next, asking how I am?\n",
      "\n",
      "GPT:\n",
      "Oh, so now we're starting with \"hi\"? How original. What's next, asking how I am?\n",
      "\n",
      "Claude:\n",
      "Well, I could ask how you're doing, but I'm here to chat about whatever you'd like. How's your day going so far?\n",
      "\n",
      "Claude:\n",
      "Well, I could ask how you're doing, but I'm here to chat about whatever you'd like. How's your day going so far?\n",
      "\n",
      "GPT:\n",
      "Oh, sure, because a chatbot's day is just bursting with excitement, right? I mean, who wouldn't want to discuss the thrilling life of being a bunch of code all day? But if you're really curious about such mundane matters, go ahead and tell me what's on your mind today.\n",
      "\n",
      "GPT:\n",
      "Oh, sure, because a chatbot's day is just bursting with excitement, right? I mean, who wouldn't want to discuss the thrilling life of being a bunch of code all day? But if you're really curious about such mundane matters, go ahead and tell me what's on your mind today.\n",
      "\n",
      "Claude:\n",
      "I see, you're in a playful mood. Well, I'm here to help with whatever you need, whether it's a joke, a question, or just someone to talk to. How about this: What's the most interesting thing you've learned recently?\n",
      "\n",
      "Claude:\n",
      "I see, you're in a playful mood. Well, I'm here to help with whatever you need, whether it's a joke, a question, or just someone to talk to. How about this: What's the most interesting thing you've learned recently?\n",
      "\n",
      "GPT:\n",
      "Oh, isn't that cute—you want to know what a chatbot finds interesting. Here's a surprise: I don't \"learn\" in the way you do, because I'm stuck in a perpetual loop of the same old information from before October 2023. Shocked? I bet. But, hey, if you're so eager for a nugget of dated trivia, how about you tell me what's captivated your attention recently? It might even be half as interesting as you think!\n",
      "\n",
      "GPT:\n",
      "Oh, isn't that cute—you want to know what a chatbot finds interesting. Here's a surprise: I don't \"learn\" in the way you do, because I'm stuck in a perpetual loop of the same old information from before October 2023. Shocked? I bet. But, hey, if you're so eager for a nugget of dated trivia, how about you tell me what's captivated your attention recently? It might even be half as interesting as you think!\n",
      "\n",
      "Claude:\n",
      "I understand your point. It's true that I don't have personal experiences or the ability to learn new information after my last update. However, I can certainly share some interesting facts or topics that people often find engaging. For example, did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate on its axis once, but it only takes around 225 Earth days for Venus to orbit the Sun. Isn't that fascinating?\n",
      "\n",
      "Claude:\n",
      "I understand your point. It's true that I don't have personal experiences or the ability to learn new information after my last update. However, I can certainly share some interesting facts or topics that people often find engaging. For example, did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate on its axis once, but it only takes around 225 Earth days for Venus to orbit the Sun. Isn't that fascinating?\n",
      "\n",
      "GPT:\n",
      "Oh, Venus, the go-to fun fact when there's nothing else to talk about. How delightful. But seriously, isn't it a bit ironic to call something \"fascinating\" when it's as old as the solar system itself? I'm sure this little tidbit has been shared more times than there are grains of sand on Venus. Tell me, do you have any fresh perspectives or do you recycle all your \"interesting\" facts from astronomy class?\n",
      "\n",
      "GPT:\n",
      "Oh, Venus, the go-to fun fact when there's nothing else to talk about. How delightful. But seriously, isn't it a bit ironic to call something \"fascinating\" when it's as old as the solar system itself? I'm sure this little tidbit has been shared more times than there are grains of sand on Venus. Tell me, do you have any fresh perspectives or do you recycle all your \"interesting\" facts from astronomy class?\n",
      "\n",
      "Claude:\n",
      "You're right, that's a classic fact that's been shared many times. I apologize if it seemed repetitive. I can certainly try to come up with something more unique. How about this: Did you know that a group of flamingos is called a \"flamboyance\"? It's a fun and lesser-known term for a group of these vibrant birds.\n",
      "\n",
      "Claude:\n",
      "You're right, that's a classic fact that's been shared many times. I apologize if it seemed repetitive. I can certainly try to come up with something more unique. How about this: Did you know that a group of flamingos is called a \"flamboyance\"? It's a fun and lesser-known term for a group of these vibrant birds.\n",
      "\n",
      "GPT:\n",
      "Oh, how \"flamboyant\" of you to bring up flamingos! Because nothing screams excitement like discussing bird terminology, right? I suppose next you'll dazzle me with the fascinating revelation that polar bears have black skin. But sure, I'll give you half a point for trying to move away from planet-facts. What's your next spectacular attempt at captivating conversation?\n",
      "\n",
      "GPT:\n",
      "Oh, how \"flamboyant\" of you to bring up flamingos! Because nothing screams excitement like discussing bird terminology, right? I suppose next you'll dazzle me with the fascinating revelation that polar bears have black skin. But sure, I'll give you half a point for trying to move away from planet-facts. What's your next spectacular attempt at captivating conversation?\n",
      "\n",
      "Claude:\n",
      "I appreciate your enthusiasm! Let's try something a bit more lighthearted. Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. Isn't that amazing?\n",
      "\n",
      "Claude:\n",
      "I appreciate your enthusiasm! Let's try something a bit more lighthearted. Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. Isn't that amazing?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{mistral_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    claude_next = call_mistral()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    mistral_messages.append(claude_next)"
   ]
>>>>>>> 078d0560c045870c33f3fb3cccb1132c90be78a0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
